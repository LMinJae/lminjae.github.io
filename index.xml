<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Min-Jae Lee</title><link>https://blog.mjlee.ga/</link><description>Recent content on Min-Jae Lee</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 18 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.mjlee.ga/index.xml" rel="self" type="application/rss+xml"/><item><title>Install Linkerd in microk8s on OCI A1 Flex</title><link>https://blog.mjlee.ga/k8s/install-linkerd-in-microk8s-on-oci-a1-flex/</link><pubDate>Mon, 18 Apr 2022 00:00:00 +0000</pubDate><guid>https://blog.mjlee.ga/k8s/install-linkerd-in-microk8s-on-oci-a1-flex/</guid><description>TL;DR When I inasll linkerd in microk8s, I receive errors like Waiting for control plane to become available on Oracle Cloud`s A1 Flex instance(ARM64) When I install microk8s in LXD, It works.
Introduction I have a problem with install linkerd in microk8s
Official install method was like below.
microk8s enable linkerd but, I recieve an errors.
Waiting for control plane to become available Cannot find Linkerd: No running pods for &amp;quot;linkerd-destination&amp;quot; Methods (Optional) Cleanup microk8s At first, I remove microk8s.</description></item><item><title>Fragmented MP4</title><link>https://blog.mjlee.ga/live-streaming/fragmented-mp4/</link><pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate><guid>https://blog.mjlee.ga/live-streaming/fragmented-mp4/</guid><description>What is Fragmented MP4 MP4 is defined in ISOBMFF.
Mandatory, minimum ISOBMFF is a set of ftyp, mdat, moov.
(def boxes-per-row 4) (draw-column-headers) (draw-box &amp;#34;ftyp&amp;#34; {:span 4}) (draw-gap &amp;#34;mdat&amp;#34;) (draw-box &amp;#34;moov&amp;#34; {:span 4}) ftyp has compatible information. mdat has real media data. moov has metadata and sample information such as data offset, size and other information that required for decode. The point of Fragmented is sample information.</description></item><item><title>RTMP</title><link>https://blog.mjlee.ga/wiki/rtmp/</link><pubDate>Thu, 31 Mar 2022 00:00:00 +0000</pubDate><guid>https://blog.mjlee.ga/wiki/rtmp/</guid><description>Adobe&amp;rsquo; Real-Time Message Protocol Introduction Summary of RTMP Protocol, consider production ready about live streaming service. From librtmp(within ffmpeg; used in obs studio), obs studio&amp;rsquo;s implementation.
Terminology The key words &amp;ldquo;MUST&amp;rdquo;, &amp;ldquo;MUST NOT&amp;rdquo;, &amp;ldquo;REQUIRED&amp;rdquo;, &amp;ldquo;SHALL&amp;rdquo;, &amp;ldquo;SHALL NOT&amp;rdquo;, &amp;ldquo;SHOULD&amp;rdquo;, &amp;ldquo;SHOULD NOT&amp;rdquo;, &amp;ldquo;RECOMMENDED&amp;rdquo;, &amp;ldquo;NOT RECOMMENDED&amp;rdquo;, &amp;ldquo;MAY&amp;rdquo;, and &amp;ldquo;OPTIONAL&amp;rdquo; in this document are to be interpreted as described in RFC2119.
Syntax Handshake Handshake Phase Version (IVersion, RVersion) RTMP protocol version negotiation.
(def boxes-per-row 4) (draw-column-headers) (draw-box &amp;#34;version&amp;#34; {:span 4}) struct hversion_t { uint8_t version; } : 8; version: Initiator send supported protocol version information.</description></item><item><title>HOTFIX: No sound</title><link>https://blog.mjlee.ga/live-streaming/20220328-hotfix-no-sound/</link><pubDate>Mon, 28 Mar 2022 00:00:00 +0000</pubDate><guid>https://blog.mjlee.ga/live-streaming/20220328-hotfix-no-sound/</guid><description>TL;DR No sound problem is due to mismatching sampling frequency index. Why On previous post, Stream by OBS have a problem, no sound playable. OBS's setting is correct that I checked by Recording. is occured by my mistake. It occured due to hard-coded frequency index in ADTS writer.
In RTMP protocol, Sampling Frequency Index was passing by AudioSpecificConfig. But, It fixed 0x1 in my tcpdump on OBS and ffmpeg.</description></item><item><title>Current status</title><link>https://blog.mjlee.ga/live-streaming/20220323-current-status/</link><pubDate>Wed, 23 Mar 2022 00:00:00 +0000</pubDate><guid>https://blog.mjlee.ga/live-streaming/20220323-current-status/</guid><description>RTMP is FLV based, so RTMP is best performance on output FLV. (Just write, without modification) As I think, In Low-latency scenario, RTMP=&amp;gt;FLV=&amp;gt;fMP4 has overhead. How about RTMP directly push fMP4 to CDN? Structure of fMP4 ISOBMFF is documented as [ISO/IEC 14496-12].
Mandatory structure is ftyp and moov, that can be found in [Table 1 — Box types, structure, and cross-reference (Informative)].
Fragment need pair of moof and mdat.</description></item><item><title>Impl. live streaming system - RTMP: Analyzy OBS studio's implementaion(librtmp-based)</title><link>https://blog.mjlee.ga/live-streaming/rtmp/analyze-obs/</link><pubDate>Mon, 07 Mar 2022 00:00:00 +0000</pubDate><guid>https://blog.mjlee.ga/live-streaming/rtmp/analyze-obs/</guid><description>Introduction There is no document that explain fully described RTMP specification. So, I don&amp;rsquo;t know what RPC methods, and there logic.
In this series&amp;rsquo;s design, Ingest receive RTMP stream from video streaming sw such as OBS studio, xsplit, or prism. And Ingest passthrough stream into transcoder that depend on ffmpeg.
I don&amp;rsquo;t know xsplit and prism&amp;rsquo;s rtmp implementation. But, OBS studio is open source and it use librtmp that rtmp implementation from ffmpeg(exactly, rtmpdump from mplayer).</description></item><item><title>Impl. live streaming system - RTMP: Chunking</title><link>https://blog.mjlee.ga/live-streaming/rtmp/chunking/</link><pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate><guid>https://blog.mjlee.ga/live-streaming/rtmp/chunking/</guid><description>Introduction Chunking provides multiplexes multiple chunk stream.
(def row-header-fn {}) (def boxes-per-row 12) (draw-box &amp;#34;Basic Header&amp;#34; {:span 3}) (draw-box &amp;#34;Message Header&amp;#34; {:span 4}) (draw-box &amp;#34;Extended Timestamp&amp;#34; {:span 5}) (draw-gap &amp;#34;Payload&amp;#34;) (draw-bottom) Default Chunk size is 128 bytes. Chunk size is maximum length of payload. So, If you want to send 200 bytes. than that message split into 2 chunk. (like below diagram)
(def row-header-fn {}) (def boxes-per-row 12) (draw-box &amp;#34;Basic Header&amp;#34; {:span 3}) (draw-box &amp;#34;Message Header&amp;#34; {:span 4}) (draw-gap &amp;#34;Payload (128 bytes)&amp;#34;) (draw-bottom) (draw-box &amp;#34;Basic Header&amp;#34; {:span 3}) (draw-gap &amp;#34;Payload (72 bytes)&amp;#34;) (draw-bottom) Header Basic header cs_id is chunk stream id that indicates following chunk&amp;rsquo;s stream context.</description></item><item><title>Impl. live streaming system - RTMP: Introduction &amp; Basic Handshake</title><link>https://blog.mjlee.ga/live-streaming/rtmp/handshake/</link><pubDate>Wed, 16 Feb 2022 00:00:00 +0000</pubDate><guid>https://blog.mjlee.ga/live-streaming/rtmp/handshake/</guid><description>Introduction RTMP Protocol is a set of these three things
Handshake Check reliable stream transport Chunk Stream Multiplexing Packetizing Message Video/Audio RPC RTMP is message multiplexing protocol, not only media service.
Adobe’s Real Time Messaging Protocol (RTMP) provides a bidirectional message multiplex service over a reliable stream transport, such as TCP [RFC0793], intended to carry parallel streams of video, audio, and data messages, with associated timing information, between a pair of communicating peers.</description></item><item><title>Impl. live streaming system: Rough design</title><link>https://blog.mjlee.ga/live-streaming/rough-design/</link><pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate><guid>https://blog.mjlee.ga/live-streaming/rough-design/</guid><description>Introduction In previous post, I select RTMP and HLS with CMAF as a protocol between service and end-users(streamers and viewers).
flowchart LR p(Streamer) subgraph Service Provider i(Ingest) t(Transcoder) e(Edge) end s(Viewer) p --&amp;gt;|RTMP| i i --&amp;gt; t t --&amp;gt; e e --&amp;gt;|HLS\CMAF| s Each layers(Ingest, Transcoder, Edge) have different requirements.
Whole system require Low-Latency, High-Available and Low-Cost.
So, detail system will be like this.
flowchart LR p(Streamer) subgraph .</description></item><item><title>Impl. live streaming system: Intro</title><link>https://blog.mjlee.ga/live-streaming/intro/</link><pubDate>Fri, 11 Feb 2022 00:00:00 +0000</pubDate><guid>https://blog.mjlee.ga/live-streaming/intro/</guid><description>Introduction I choose live streaming as the first project for posting. because it can be expanded widely in these days and future.
This article is a decision to select protocols for both streamer and viewer.
Define live streaming as Real-Time(low-latency) Video/Audio Delivery service. live streaming + low latency bi-directional communication =&amp;gt; game streaming service In this series, I want to cover the whole flow are explained below from scratch as possible as possible.</description></item></channel></rss>